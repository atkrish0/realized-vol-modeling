{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 27233,
          "databundleVersionId": 2344753,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30140,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ffe3f16c2274ef4a5121191c8edacd4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cd8e2299293b46c38b84354674df36f5",
            "msg_id": "",
            "outputs": []
          }
        },
        "cd8e2299293b46c38b84354674df36f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40d18041b3c42548175e0782aefe55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d310253b41014ceb9a27cdf820e5dfe4",
              "IPY_MODEL_41c05549abff402486b05ed322469742",
              "IPY_MODEL_05cd9782e2474d6b86a2f003e33084d2"
            ],
            "layout": "IPY_MODEL_d1e5f44834904bd1ba788eb70a37950c"
          }
        },
        "d310253b41014ceb9a27cdf820e5dfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66bba6e6ff604064ba557e97db75b213",
            "placeholder": "​",
            "style": "IPY_MODEL_0a5352337518425587a11a8c5c471a90",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "41c05549abff402486b05ed322469742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a531ccd6964397984a5e05b77c5f98",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dce12b25ba2c4362bbf2e5db55c1750c",
            "value": 2
          }
        },
        "05cd9782e2474d6b86a2f003e33084d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caf0876a96a7496b9c87ce76ff0360d6",
            "placeholder": "​",
            "style": "IPY_MODEL_c1933a470ac043e19d168d74c9b5f564",
            "value": " 2/2 [00:00&lt;00:00, 15.69it/s]"
          }
        },
        "d1e5f44834904bd1ba788eb70a37950c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "66bba6e6ff604064ba557e97db75b213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5352337518425587a11a8c5c471a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42a531ccd6964397984a5e05b77c5f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce12b25ba2c4362bbf2e5db55c1750c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caf0876a96a7496b9c87ce76ff0360d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1933a470ac043e19d168d74c9b5f564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I've made this notebook to demonstrate my solution, you can read detailed explanation [here](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/279170). It doesn't include full CV and inference, instead I tried to make it short and include only key elements: preprocessing and NN architecture. I did a lot of refactoring to simplify my code and to fit kaggle RAM limitations, it might affect performance a bit, but hopefully not so much.\n",
        "\n",
        "One thing that I changed is data preprocessing using xarray instead of pandas - I really liked how well it fit multidimensional nature of the data. It speed up many group by operations by replacing them with aggregations over array dimensions.\n",
        "\n",
        "Here I also include 2 modes of training: *single-stock* and *multi-stock*. *multi-stock* training works really fast and you can get decent results after 20 minutes. In this mode train batch includes targets for all stocks in time_id and you have only 3830 training samples. In *single-stock* mode input is still the same and includes data from all stocks, but it also has single stock_id as input and only single stock target for it is predicted. This way batch contains much more diverse (stock_id, time_id) pairs, and I believe this diversity is important to get better score. During the competition I used *single-stock* training, despite much longer training times. Usually my public score was better than my validation score by 0.005-0.006. My best single models without using nearest neigbours scored ~0.199-0.200 on public while validation score was ~0.206. In *multi-stock* mode I can achieve currently only ~0.210-0.211 score, though I haven't tried to wait until training end in *single-stock* mode after refactoring, but it should be better.\n",
        "\n",
        "Anyway this just a baseline, and there are a lot of things to experiment with: stock attention placement (before/after RNN and internal implementation, feature normalization (you should probably do something with volumes as the way I did it didn't work well on private test), network dimensions, batch size, lr, etc."
      ],
      "metadata": {
        "id": "IysNA2h61bz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install einops\n",
        "!pip install lightning --quiet\n",
        "#!pip install pytorch-lightning==1.5.10 --quiet"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T22:20:00.850814Z",
          "iopub.execute_input": "2025-04-15T22:20:00.851113Z",
          "iopub.status.idle": "2025-04-15T22:20:08.462014Z",
          "shell.execute_reply.started": "2025-04-15T22:20:00.851024Z",
          "shell.execute_reply": "2025-04-15T22:20:08.461032Z"
        },
        "id": "1RDJ92DA1bz4"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import einops\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import ipywidgets as widgets\n",
        "from joblib import Parallel, delayed\n",
        "import torch\n",
        "from torch import nn\n",
        "#import pytorch_lightning as pl\n",
        "import lightning.pytorch as pl\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T22:20:12.392162Z",
          "iopub.execute_input": "2025-04-15T22:20:12.392899Z",
          "iopub.status.idle": "2025-04-15T22:20:18.450201Z",
          "shell.execute_reply.started": "2025-04-15T22:20:12.392861Z",
          "shell.execute_reply": "2025-04-15T22:20:18.449533Z"
        },
        "id": "ixGEC9j_1bz5"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/RBS DL 2025/PRO/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8PM9w3PSFNc",
        "outputId": "4c697f40-4986-4ed3-db2c-52118dee8695"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 21\n",
        "n_stocks = 112\n",
        "n_seconds = 600\n",
        "# if coarsen > 1, data will be aggregated per this number of seconds,\n",
        "# use this to reduce memory usage, though during competition I trained on full data,\n",
        "# so I'm not sure how it can affect model performance\n",
        "coarsen = 3"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T22:20:31.692157Z",
          "iopub.execute_input": "2025-04-15T22:20:31.692854Z",
          "iopub.status.idle": "2025-04-15T22:20:31.696431Z",
          "shell.execute_reply.started": "2025-04-15T22:20:31.692822Z",
          "shell.execute_reply": "2025-04-15T22:20:31.695660Z"
        },
        "id": "nENivPyq1bz6"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(stock_id, stock_ind, set, time_ids, coarsen, norm, out):\n",
        "    #load book data\n",
        "    df_book = pd.read_parquet(f'{data_dir}/book_{set}.parquet/stock_id={stock_id}')\n",
        "    df_min_second = df_book.groupby('time_id').agg(min_second=('seconds_in_bucket', 'min'))\n",
        "    df_book = df_book.merge(df_min_second, left_on='time_id', right_index=True) \\\n",
        "        .eval('seconds_in_bucket = seconds_in_bucket - min_second') \\\n",
        "        .drop('min_second', axis=1)\n",
        "    # load trade data\n",
        "    df_trade = pd.read_parquet(f'{data_dir}/trade_{set}.parquet/stock_id={stock_id}') \\\n",
        "        .merge(df_min_second, left_on='time_id', right_index=True) \\\n",
        "        .eval('seconds_in_bucket = seconds_in_bucket - min_second') \\\n",
        "        .drop('min_second', axis=1)\n",
        "    # merge book + trade\n",
        "    df = pd.merge(df_book, df_trade, on=['time_id', 'seconds_in_bucket'], how='outer')\n",
        "    df['stock_id'] = stock_id\n",
        "    # set multi index\n",
        "    df = df.set_index(['stock_id', 'time_id', 'seconds_in_bucket'])\n",
        "    # pandas -> xarray\n",
        "    df = df.to_xarray().astype('float32')\n",
        "    # processing seconds col to make sure it works fine\n",
        "    df = df.reindex({'time_id': time_ids, 'seconds_in_bucket': np.arange(n_seconds)})\n",
        "    # forward fill imputation: if no new quote, old quote stays active\n",
        "    for name in ['bid_price1', 'bid_price2', 'ask_price1', 'ask_price2',\n",
        "         'bid_size1', 'bid_size2', 'ask_size1', 'ask_size2']:\n",
        "        df[name] = df[name].ffill('seconds_in_bucket')\n",
        "    # wap1/2\n",
        "    df['wap1'] = (df.bid_price1 * df.ask_size1 + df.ask_price1 * df.bid_size1) / (df.bid_size1 + df.ask_size1)\n",
        "    df['wap2'] = (df.bid_price2 * df.ask_size2 + df.ask_price2 * df.bid_size2) / (df.bid_size2 + df.ask_size2)\n",
        "    # log(wap1/2)\n",
        "    df['log_return1'] = np.log(df.wap1).diff('seconds_in_bucket')\n",
        "    df['log_return2'] = np.log(df.wap2).diff('seconds_in_bucket')\n",
        "    df['current_vol'] = (df.log_return1 ** 2).sum('seconds_in_bucket') ** 0.5\n",
        "    df['current_vol_2nd_half'] = (df.log_return1[..., 300:] ** 2).sum('seconds_in_bucket') ** 0.5\n",
        "    # downsmapling if coursen > 1\n",
        "    if coarsen > 1:\n",
        "        mean_features = ['ask_price1', 'ask_price2', 'bid_price1', 'bid_price2',  'ask_size1', 'ask_size2',\n",
        "               'bid_size1', 'bid_size2', 'price']\n",
        "        sum_features = ['size', 'order_count']\n",
        "\n",
        "        df = xr.merge((df[mean_features].coarsen({'seconds_in_bucket': coarsen}, coord_func='min').mean(),\n",
        "                       df[sum_features].coarsen({'seconds_in_bucket': coarsen}, coord_func='min').sum(),\n",
        "                       df[['current_vol', 'current_vol_2nd_half']]))\n",
        "        df['wap1'] = (df.bid_price1 * df.ask_size1 + df.ask_price1 * df.bid_size1) / (df.bid_size1 + df.ask_size1)\n",
        "        df['wap2'] = (df.bid_price2 * df.ask_size2 + df.ask_price2 * df.bid_size2) / (df.bid_size2 + df.ask_size2)\n",
        "        df['log_return1'] = np.log(df.wap1).diff('seconds_in_bucket')\n",
        "        df['log_return2'] = np.log(df.wap2).diff('seconds_in_bucket')\n",
        "    # ba spread\n",
        "    df['spread1'] = df.ask_price1 - df.bid_price1\n",
        "    # order book slope\n",
        "    df['spread2'] = df.ask_price2 - df.ask_price1\n",
        "    df['spread3'] = df.bid_price1 - df.bid_price2\n",
        "    df['total_volume'] = df.ask_size1 + df.ask_size2 + df.bid_size1 + df.bid_size2\n",
        "    df['volume_imbalance1'] = df.ask_size1 + df.ask_size2 - df.bid_size1 - df.bid_size2\n",
        "    df['volume_imbalance2'] = (df.ask_size1 + df.ask_size2 - df.bid_size1 - df.bid_size2) / df.total_volume\n",
        "    for name in ['bid_size1', 'bid_size2', 'ask_size1', 'ask_size2', 'size', 'order_count', 'total_volume']:\n",
        "        df[name] = np.log1p(df[name])\n",
        "        # df[name] = df[name].rank('seconds_in_bucket')\n",
        "    df['volume_imbalance1'] = np.sign(df['volume_imbalance1']) * np.log1p(abs(df['volume_imbalance1']))\n",
        "\n",
        "    df = df.fillna({'ask_price1': 1, 'ask_price2': 1, 'bid_price1': 1, 'bid_price2': 1,  'ask_size1': 0, 'ask_size2': 0,\n",
        "               'bid_size1': 0, 'bid_size2': 0, 'price': 1, 'size': 0, 'order_count': 0, 'wap1': 1, 'wap2': 1,\n",
        "               'log_return1': 0, 'log_return2': 0, 'spread1': 0, 'spread2': 0, 'spread3': 0, 'total_volume': 0,\n",
        "               'volume_imbalance1': 0, 'volume_imbalance2': 0, 'current_vol': 0, 'current_vol_2nd_half': 0})\n",
        "    features = ['ask_price1', 'ask_price2', 'bid_price1', 'bid_price2',  'ask_size1', 'ask_size2',\n",
        "               'bid_size1', 'bid_size2', 'price', 'size', 'order_count', 'wap1', 'wap2',\n",
        "               'log_return1', 'log_return2', 'spread1', 'spread2', 'spread3', 'total_volume',\n",
        "               'volume_imbalance1', 'volume_imbalance2']\n",
        "    extra = ['current_vol', 'current_vol_2nd_half']\n",
        "\n",
        "    if norm is not None:\n",
        "        mean = norm['mean'].sel(stock_id=stock_id)\n",
        "        std = norm['std'].sel(stock_id=stock_id)\n",
        "    else:\n",
        "        mean = df.mean(('time_id', 'seconds_in_bucket')).drop(['current_vol', 'current_vol_2nd_half'])\n",
        "        std = df.std(('time_id', 'seconds_in_bucket')).drop(['current_vol', 'current_vol_2nd_half'])\n",
        "\n",
        "    df.update((df - mean) / std)\n",
        "    df = df.astype('float32')\n",
        "\n",
        "    out[:, stock_ind] = einops.rearrange(df[features].to_array().values, 'f () t sec -> t sec f')\n",
        "    return df[extra], {'mean': mean, 'std': std}"
      ],
      "metadata": {
        "id": "XQR4Rzfvc4HH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch dataset: feeds data into model while training\n",
        "class OptiverDataset(Dataset):\n",
        "    def __init__(self, features_data, extra_data, mode, time_ids):\n",
        "        self.features_data = features_data\n",
        "        # targets and current_vol\n",
        "        self.extra_data = extra_data\n",
        "        self.time_ids = time_ids\n",
        "        self.mode = mode\n",
        "\n",
        "    # tells the number of samples to pytorch\n",
        "    def __len__(self):\n",
        "        if self.mode == 'single-stock':\n",
        "            return len(self.time_ids) * n_stocks\n",
        "        elif self.mode == 'multi-stock':\n",
        "            return len(self.time_ids)\n",
        "\n",
        "    # for a given index i, return the corresponding input features + labels for model training.\n",
        "    def __getitem__(self, i):\n",
        "        if self.mode == 'single-stock':\n",
        "            time_id = self.time_ids[i // n_stocks]\n",
        "            time_ind = self.extra_data.indexes['time_id'].get_loc(time_id)\n",
        "            stock_ind = i % n_stocks\n",
        "            stock_id = self.extra_data.indexes['stock_id'][stock_ind]\n",
        "            return {\n",
        "                'data': self.features_data[time_ind], # (112, 600, 21)\n",
        "                'target': self.extra_data['target'].values[time_ind, stock_ind],  # (1,)\n",
        "                'current_vol': self.extra_data['current_vol'].values[time_ind, stock_ind],  # (1,)\n",
        "                'current_vol_2nd_half': self.extra_data['current_vol_2nd_half'].values[time_ind, stock_ind],  # (1,)\n",
        "                'time_id': time_id,\n",
        "                'stock_id': stock_id,\n",
        "                'stock_ind': stock_ind\n",
        "            }\n",
        "        elif self.mode == 'multi-stock':\n",
        "            time_id = self.time_ids[i]\n",
        "            time_ind = self.extra_data.indexes['time_id'].get_loc(time_id)\n",
        "            return {\n",
        "                'data': self.features_data[time_ind], # (112, 600, 21)\n",
        "                'target': self.extra_data['target'].values[time_ind],  # (112,)\n",
        "                'current_vol': self.extra_data['current_vol'].values[time_ind],  # (112,)\n",
        "                'current_vol_2nd_half': self.extra_data['current_vol_2nd_half'].values[time_ind],  # (112,)\n",
        "                'time_id': time_id,\n",
        "            }"
      ],
      "metadata": {
        "id": "D3Yq6DARdG0M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Attention Intuition:\n",
        "\n",
        "Maybe volatility spikes at the beginning of a window. Or maybe at the end of a window. Fixed pooling (mean, max) can't adapt to this. This TimeAttention layer learns to adapt dynamically based on data patterns."
      ],
      "metadata": {
        "id": "NOuRz3GP4ccR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# not all seconds are equally informative — attention helps model prioritize\n",
        "class TimeAttention(nn.Module):\n",
        "    # learn which parts of the time window are important\n",
        "    def __init__(self, steps):\n",
        "        super().__init__()\n",
        "        self.steps = steps\n",
        "        self.weights = nn.Parameter(torch.zeros(steps))\n",
        "\n",
        "    # the forward pass - collpases time dimension in a weighted manner\n",
        "    def forward(self, x):\n",
        "        # x: (b, st, t, f)\n",
        "        attn = F.softmax(self.weights, 0)\n",
        "        x = torch.einsum('b s t f, t -> b s f', x, attn)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hh0XK_9zg_xV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stock Attention Intuition:\n",
        "Each stock might borrow information from other correlated stocks.\n",
        "\n",
        "Example:\n",
        "\n",
        "If stock_10 and stock_25 usually move together, attention will learn to pull information between them. Helps the model generalize better, especially when market events affect multiple stocks."
      ],
      "metadata": {
        "id": "riH_2FSi4O9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can experiment with other ideas for stock attention: maybe it could be\n",
        "# something like MultiHeadAttention module with keys and queries that depends on current input,\n",
        "# maybe it could be a linear combination of all stocks (full connected layer),maybe you can try sparse softmax\n",
        "\n",
        "class StockAttention(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.zeros((n_stocks, n_stocks)))\n",
        "        self.bias = nn.Parameter(torch.zeros(n_stocks))\n",
        "        self.fc_combine = nn.Linear(dim * 2, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, stock, time, feature)\n",
        "        # compute attention scores across assets\n",
        "        attn = F.softmax(self.weight + self.bias[None, :], dim = -1) # (st, st)\n",
        "        y = torch.einsum('b i ..., j i -> b j ...', x, attn)\n",
        "        x = torch.cat((x, y), -1)\n",
        "        x = self.fc_combine(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vnckGz131W8x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptiverModel(pl.LightningModule):\n",
        "    def __init__(self, mode='multi-stock', dim=32, conv1_kernel=3, rnn_layers=2, rnn_dropout=0.3,\n",
        "                 n_features=21, aux_loss_weight=1.0):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        # stpck specific embeddings\n",
        "        self.stock_emb = nn.Embedding(n_stocks, dim)\n",
        "        self.stock_emb.weight.data.normal_(0, 0.2)\n",
        "        # 1D convolution across time for feature extraction\n",
        "        self.conv1 = nn.Conv1d(n_features, dim, conv1_kernel, conv1_kernel)\n",
        "        self.conv2 = nn.Conv1d(dim, dim, 1, 1)\n",
        "        # Normalize features to stabilize training\n",
        "        self.norm1 = nn.LayerNorm([n_stocks, dim])\n",
        "        self.norm2 = nn.LayerNorm([n_stocks, dim])\n",
        "        self.rnn = nn.GRU(dim, dim, rnn_layers, batch_first=True, dropout=rnn_dropout)\n",
        "        # attention over time dimension\n",
        "        self.timesteps_attn = TimeAttention(600 // conv1_kernel // coarsen) # full window\n",
        "        self.timesteps_attn2 = TimeAttention(300 // conv1_kernel // coarsen) # half window\n",
        "        # attention over stock\n",
        "        self.stock_attn = StockAttention(dim)\n",
        "        # final prediction heads\n",
        "        self.fc_out1 = nn.Linear(dim, 1)\n",
        "        self.fc_out2 = nn.Linear(dim, 1)\n",
        "        # store perfromance over epochs\n",
        "        self.history = pd.DataFrame()\n",
        "\n",
        "    def forward(self, x, stock_ind=None):\n",
        "        # x: (b, st, t, f)\n",
        "        x = einops.rearrange(x, 'b st t f -> (b st) f t')\n",
        "        x = self.conv1(x)\n",
        "        x = einops.rearrange(x, '(b st) f t -> b t st f', st=n_stocks)\n",
        "        x = F.gelu(x)\n",
        "        x = self.norm1(x)\n",
        "        x = einops.rearrange(x, 'b t st f -> (b st) f t')\n",
        "        x = self.conv2(x)\n",
        "        x = einops.rearrange(x, '(b st) f t -> b t st f', st=n_stocks)\n",
        "        x = F.gelu(x)\n",
        "        x = self.norm2(x)\n",
        "        x = einops.rearrange(x, 'b t st f -> b st t f')\n",
        "        x = self.stock_attn(x)\n",
        "        x = x + self.stock_emb.weight[None, :, None, :]\n",
        "        if self.hparams.mode == 'single-stock':\n",
        "            x = x[torch.arange(len(x)), stock_ind][:, None]\n",
        "        x = einops.rearrange(x, 'b st t f -> (b st) t f')\n",
        "        x = self.rnn(x)[0]\n",
        "        x = einops.rearrange(x, '(b st) t f -> b st t f', st=n_stocks if self.hparams.mode == 'multi-stock' else 1)\n",
        "        x1 = self.timesteps_attn(x)\n",
        "        x2 = self.timesteps_attn2(x[:, :, :self.timesteps_attn2.steps, :])\n",
        "        x1 = self.fc_out1(x1)\n",
        "        x2 = self.fc_out2(x2)\n",
        "        x1 = x1 * 0.63393 - 5.762331\n",
        "        x2 = x2 * 0.67473418 - 6.098946\n",
        "        x1 = torch.exp(x1)\n",
        "        x2 = torch.exp(x2)\n",
        "        if self.hparams.mode == 'single-stock':\n",
        "            return {\n",
        "                'vol': x1[:, 0, 0], # (b,)\n",
        "                'vol2': x2[:, 0, 0] # (b,)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'vol': x1[..., 0], # (b, st)\n",
        "                'vol2': x2[..., 0] # (b, st)\n",
        "            }\n",
        "\n",
        "    def training_step(self, batch, batch_ind):\n",
        "        out = self.common_step(batch, 'train')\n",
        "        return out\n",
        "\n",
        "    def validation_step(self, batch, batch_ind):\n",
        "        return self.common_step(batch, 'valid')\n",
        "\n",
        "    def common_step(self, batch, stage):\n",
        "        out = self(batch['data'], batch['stock_ind'] if self.hparams.mode == 'single-stock' else None)\n",
        "        mask1 = ~torch.isnan(batch['target'])\n",
        "        target1 = torch.where(mask1, batch['target'], torch.tensor(1.0, device=self.device))\n",
        "        mask2 = batch['current_vol_2nd_half'] > 0\n",
        "        target2 = torch.where(mask2, batch['current_vol_2nd_half'], torch.tensor(1.0, device=self.device))\n",
        "        vol_loss = (((out['vol'] - target1) / target1) ** 2)[mask1].mean() ** 0.5\n",
        "        vol2_loss = (((out['vol2'] - target2) / target2) ** 2)[mask2].mean() ** 0.5\n",
        "        loss = vol_loss + self.hparams.aux_loss_weight * vol2_loss\n",
        "        self.log(f'{stage}/loss', loss.item(), on_step=False, on_epoch=True)\n",
        "        self.log(f'{stage}/vol_loss', vol_loss.item(), on_step=False, on_epoch=True)\n",
        "        self.log(f'{stage}/vol2_loss', vol2_loss.item(), on_step=False, on_epoch=True)\n",
        "        return {\n",
        "            'loss': loss,\n",
        "            'target': batch['target'],\n",
        "            'vol': out['vol'].detach(),\n",
        "            'time_id': batch['time_id']\n",
        "        }\n",
        "\n",
        "    def common_epoch_end(self, outs, stage):\n",
        "        target = torch.cat([x['target'] for x in outs])\n",
        "        vol = torch.cat([x['vol'] for x in outs])\n",
        "        time_ids = torch.cat([x['time_id'] for x in outs])\n",
        "        mask = ~torch.isnan(target)\n",
        "        target = torch.where(mask, target, torch.tensor(1.0, device=self.device))\n",
        "        rmspe = (((vol - target) / target) ** 2)[mask].mean() ** 0.5\n",
        "        self.log(f'{stage}/rmspe', rmspe, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.history.loc[self.trainer.current_epoch, f'{stage}/rmspe'] = rmspe.item()\n",
        "\n",
        "    def on_train_epoch_end(self, outputs):\n",
        "        self.common_epoch_end(outputs, 'train')\n",
        "        self.history_widget.clear_output(wait=True)\n",
        "        with self.history_widget:\n",
        "            ylim = [self.history.min().min(), self.history.quantile(0.95).max()]\n",
        "            ylim[0] -= (ylim[1] - ylim[0]) * 0.05\n",
        "            self.history.plot(color=['C1', 'C0'], style=['--', '-'], ylim=ylim)\n",
        "            plt.show()\n",
        "\n",
        "    def on_validation_epoch_end(self, outputs):\n",
        "        self.common_epoch_end(outputs, 'valid')\n",
        "\n",
        "    def on_fit_start(self):\n",
        "        self.history_widget = widgets.Output()\n",
        "        display(self.history_widget)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = Adam(self.parameters(), lr=0.001)\n",
        "        # opt = Adam(self.parameters(), lr=0.0005) # single-stock\n",
        "        sched = {\n",
        "            'scheduler': ExponentialLR(opt, 0.93),\n",
        "        # 'scheduler': ExponentialLR(opt, 0.9), #  single-stock\n",
        "            'interval': 'epoch'\n",
        "        }\n",
        "        return [opt], [sched]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T22:20:55.494582Z",
          "iopub.execute_input": "2025-04-15T22:20:55.494823Z",
          "iopub.status.idle": "2025-04-15T22:20:55.542312Z",
          "shell.execute_reply.started": "2025-04-15T22:20:55.494800Z",
          "shell.execute_reply": "2025-04-15T22:20:55.541518Z"
        },
        "id": "xF1iKEUv1bz6"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG1rDxvbe_Id",
        "outputId": "22ceabb1-78bf-4d23-e413-7fe966a00a57"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(f'{data_dir}/train.csv')\n",
        "train_data = np.memmap('/content/drive/MyDrive/Colab Notebooks/RBS DL 2025/PRO/train.npy', 'float16', 'w+',\n",
        "                       shape=(df_train.time_id.nunique(), n_stocks, n_seconds // coarsen, n_features))\n",
        "\n",
        "res = Parallel(n_jobs=4, verbose=51)(\n",
        "    delayed(prepare_data)(stock_id, stock_ind, 'train', df_train.time_id.unique(), coarsen, None, train_data)\n",
        "    for stock_ind, stock_id in enumerate(df_train.stock_id.unique())\n",
        ")\n",
        "\n",
        "train_extra = xr.concat([x[0] for x in res], 'stock_id')\n",
        "train_extra['target'] = df_train.set_index(['time_id', 'stock_id']).to_xarray()['target'].astype('float32')\n",
        "train_extra = train_extra.transpose('time_id', 'stock_id')\n",
        "train_norm = {\n",
        "    'mean': xr.concat([x[1]['mean'] for x in res], 'stock_id'),\n",
        "    'std': xr.concat([x[1]['std'] for x in res], 'stock_id')\n",
        "}\n",
        "\n",
        "# if you data fits in memory, you can load it entirely from disk, otherwise\n",
        "# training in single-stock mode could be very slow, though it can be OK for multi-stock mode\n",
        "train_data = np.array(train_data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T22:58:10.573017Z",
          "iopub.execute_input": "2025-04-15T22:58:10.573632Z",
          "iopub.status.idle": "2025-04-15T23:00:10.620863Z",
          "shell.execute_reply.started": "2025-04-15T22:58:10.573597Z",
          "shell.execute_reply": "2025-04-15T23:00:10.620216Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ5t_0Ux1bz7",
        "outputId": "d3da724a-85d7-45e6-fde1-fd74663321fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   26.7s\n",
            "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   38.9s\n",
            "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:   38.9s\n",
            "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:   38.9s\n",
            "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:   38.9s\n",
            "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:   50.8s\n",
            "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   50.9s\n",
            "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:   50.9s\n",
            "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:   50.9s\n",
            "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=4)]: Done 108 out of 112 | elapsed:  6.1min remaining:   13.6s\n",
            "[Parallel(n_jobs=4)]: Done 112 out of 112 | elapsed:  6.3min finished\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(5, shuffle=True, random_state=1)\n",
        "time_ids = train_extra.indexes['time_id'].values\n",
        "train_time_ids, val_time_ids = next(cv.split(time_ids))\n",
        "\n",
        "# multi-stock training (fast)\n",
        "train_ds = OptiverDataset(train_data, train_extra, 'multi-stock', time_ids[train_time_ids])\n",
        "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=1, pin_memory=True, persistent_workers=True)\n",
        "val_ds = OptiverDataset(train_data, train_extra, 'multi-stock', time_ids[val_time_ids])\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=1, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "# single-stock training (slow)\n",
        "# train_ds = OptiverDataset(train_data, train_extra, 'single-stock', time_ids[train_time_ids])\n",
        "# train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=1, pin_memory=True, persistent_workers=True)\n",
        "# val_ds = OptiverDataset(train_data, train_extra, 'single-stock', time_ids[val_time_ids])\n",
        "# val_dl = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=1, pin_memory=True, persistent_workers=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:01:31.524390Z",
          "iopub.execute_input": "2025-04-15T23:01:31.524950Z",
          "iopub.status.idle": "2025-04-15T23:01:31.533220Z",
          "shell.execute_reply.started": "2025-04-15T23:01:31.524915Z",
          "shell.execute_reply": "2025-04-15T23:01:31.532478Z"
        },
        "id": "5bMAxU_e1bz8"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "model = OptiverModel(mode='multi-stock', dim=32, conv1_kernel=1, aux_loss_weight=1) # multi-stock\n",
        "# model = OptiverModel(mode='single-stock', conv1_kernel=1, aux_loss_weight=0) # single-stock\n",
        "# model.summarize(max_depth=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:01:56.636474Z",
          "iopub.execute_input": "2025-04-15T23:01:56.636733Z",
          "iopub.status.idle": "2025-04-15T23:01:56.679045Z",
          "shell.execute_reply.started": "2025-04-15T23:01:56.636706Z",
          "shell.execute_reply": "2025-04-15T23:01:56.678358Z"
        },
        "id": "FTbJF0W71bz8"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = pl.Trainer(gpus=1, precision=16, max_epochs=10) # multi-stock\n",
        "trainer = pl.Trainer(devices=1, accelerator=\"gpu\", precision=16, max_epochs=10) # multi-stock\n",
        "# trainer = pl.Trainer(gpus=1, precision=16, limit_train_batches=2500, max_epochs=25) # single-stock"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:02:01.583926Z",
          "iopub.execute_input": "2025-04-15T23:02:01.584626Z",
          "iopub.status.idle": "2025-04-15T23:02:01.652422Z",
          "shell.execute_reply.started": "2025-04-15T23:02:01.584590Z",
          "shell.execute_reply": "2025-04-15T23:02:01.651760Z"
        },
        "id": "YkErma7h1bz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fda76a0-16aa-4461-aa60-a815f42da5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, train_dl, val_dl)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:02:04.857675Z",
          "iopub.execute_input": "2025-04-15T23:02:04.858321Z",
          "iopub.status.idle": "2025-04-15T23:28:46.468892Z",
          "shell.execute_reply.started": "2025-04-15T23:02:04.858287Z",
          "shell.execute_reply": "2025-04-15T23:28:46.468120Z"
        },
        "id": "o5TzGl2i1bz-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7ffe3f16c2274ef4a5121191c8edacd4",
            "cd8e2299293b46c38b84354674df36f5",
            "a40d18041b3c42548175e0782aefe55d",
            "d310253b41014ceb9a27cdf820e5dfe4",
            "41c05549abff402486b05ed322469742",
            "05cd9782e2474d6b86a2f003e33084d2",
            "d1e5f44834904bd1ba788eb70a37950c",
            "66bba6e6ff604064ba557e97db75b213",
            "0a5352337518425587a11a8c5c471a90",
            "42a531ccd6964397984a5e05b77c5f98",
            "dce12b25ba2c4362bbf2e5db55c1750c",
            "caf0876a96a7496b9c87ce76ff0360d6",
            "c1933a470ac043e19d168d74c9b5f564"
          ]
        },
        "outputId": "b0e43266-0533-49a7-e2a6-1c4bf077146f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "   | Name            | Type           | Params | Mode \n",
            "------------------------------------------------------------\n",
            "0  | stock_emb       | Embedding      | 3.6 K  | train\n",
            "1  | conv1           | Conv1d         | 704    | train\n",
            "2  | conv2           | Conv1d         | 1.1 K  | train\n",
            "3  | norm1           | LayerNorm      | 7.2 K  | train\n",
            "4  | norm2           | LayerNorm      | 7.2 K  | train\n",
            "5  | rnn             | GRU            | 12.7 K | train\n",
            "6  | timesteps_attn  | TimeAttention  | 200    | train\n",
            "7  | timesteps_attn2 | TimeAttention  | 100    | train\n",
            "8  | stock_attn      | StockAttention | 14.7 K | train\n",
            "9  | fc_out1         | Linear         | 33     | train\n",
            "10 | fc_out2         | Linear         | 33     | train\n",
            "------------------------------------------------------------\n",
            "47.5 K    Trainable params\n",
            "0         Non-trainable params\n",
            "47.5 K    Total params\n",
            "0.190     Total estimated model params size (MB)\n",
            "12        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "   | Name            | Type           | Params | Mode \n",
            "------------------------------------------------------------\n",
            "0  | stock_emb       | Embedding      | 3.6 K  | train\n",
            "1  | conv1           | Conv1d         | 704    | train\n",
            "2  | conv2           | Conv1d         | 1.1 K  | train\n",
            "3  | norm1           | LayerNorm      | 7.2 K  | train\n",
            "4  | norm2           | LayerNorm      | 7.2 K  | train\n",
            "5  | rnn             | GRU            | 12.7 K | train\n",
            "6  | timesteps_attn  | TimeAttention  | 200    | train\n",
            "7  | timesteps_attn2 | TimeAttention  | 100    | train\n",
            "8  | stock_attn      | StockAttention | 14.7 K | train\n",
            "9  | fc_out1         | Linear         | 33     | train\n",
            "10 | fc_out2         | Linear         | 33     | train\n",
            "------------------------------------------------------------\n",
            "47.5 K    Trainable params\n",
            "0         Non-trainable params\n",
            "47.5 K    Total params\n",
            "0.190     Total estimated model params size (MB)\n",
            "12        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ffe3f16c2274ef4a5121191c8edacd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a40d18041b3c42548175e0782aefe55d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "OptiverModel.on_validation_epoch_end() missing 1 required positional argument: 'outputs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ce7f28d606a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_iteration_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_dataloader_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_run_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mon_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_evaluation_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mlogged_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# free memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_on_evaluation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"on_test_epoch_end\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"on_validation_epoch_end\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_lightning_module_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: OptiverModel.on_validation_epoch_end() missing 1 required positional argument: 'outputs'"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best epoch {model.history[\"valid/rmspe\"].argmin()}: {model.history[\"valid/rmspe\"].min()}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:38:39.817143Z",
          "iopub.execute_input": "2025-04-15T23:38:39.817911Z",
          "iopub.status.idle": "2025-04-15T23:38:39.823936Z",
          "shell.execute_reply.started": "2025-04-15T23:38:39.817858Z",
          "shell.execute_reply": "2025-04-15T23:38:39.823187Z"
        },
        "id": "FRwgAWXZ1bz_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(F.softmax(model.timesteps_attn.weights, 0).detach()).plot();"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:38:47.150546Z",
          "iopub.execute_input": "2025-04-15T23:38:47.151192Z",
          "iopub.status.idle": "2025-04-15T23:38:47.289125Z",
          "shell.execute_reply.started": "2025-04-15T23:38:47.151159Z",
          "shell.execute_reply": "2025-04-15T23:38:47.288397Z"
        },
        "id": "9ICw_lSV1bz_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.matshow(F.softmax((model.stock_attn.weight + model.stock_attn.bias[None, :]).detach(), -1), fignum=0, norm=mpl.colors.PowerNorm(0.5));"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:39:34.418759Z",
          "iopub.execute_input": "2025-04-15T23:39:34.419446Z",
          "iopub.status.idle": "2025-04-15T23:39:34.619900Z",
          "shell.execute_reply.started": "2025-04-15T23:39:34.419415Z",
          "shell.execute_reply": "2025-04-15T23:39:34.619033Z"
        },
        "id": "jd9XROu81b0A"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.matshow(model.stock_emb.weight.detach(), fignum=0);"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-15T23:39:35.398605Z",
          "iopub.execute_input": "2025-04-15T23:39:35.399206Z",
          "iopub.status.idle": "2025-04-15T23:39:35.681910Z",
          "shell.execute_reply.started": "2025-04-15T23:39:35.399175Z",
          "shell.execute_reply": "2025-04-15T23:39:35.681047Z"
        },
        "id": "nV0PwrwW1b0A"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/drive/MyDrive/Colab Notebooks/RBS DL 2025/PRO/train.npy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-26T17:59:25.529634Z",
          "iopub.execute_input": "2025-03-26T17:59:25.530545Z",
          "iopub.status.idle": "2025-03-26T17:59:27.665585Z",
          "shell.execute_reply.started": "2025-03-26T17:59:25.530496Z",
          "shell.execute_reply": "2025-03-26T17:59:27.664393Z"
        },
        "id": "IwnDnw481b0A"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}