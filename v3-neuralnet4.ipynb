{"cells":[{"cell_type":"markdown","metadata":{"id":"aO1upiHT1011"},"source":["PURPOSE: REMOVE SINGLE STOCK MENTIONS"]},{"cell_type":"markdown","metadata":{"id":"IysNA2h61bz2"},"source":["[REF](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/279170).\n","\n","Here I also include 2 modes of training: *single-stock* and *multi-stock*. *multi-stock* training works really fast and you can get decent results after 20 minutes. In this mode train batch includes targets for all stocks in time_id and you have only 3830 training samples. In *single-stock* mode input is still the same and includes data from all stocks, but it also has single stock_id as input and only single stock target for it is predicted. This way batch contains much more diverse (stock_id, time_id) pairs, and I believe this diversity is important to get better score.\n","\n","Future Scope:\n","- stock attention placement (before/after RNN and internal implementation\n","- feature normalization (something with volumes),\n","- network dimensions, batch size, lr, etc."]},{"cell_type":"markdown","metadata":{"id":"Fa8hBEYiQaOA"},"source":["**Model Summary:**\n","\n","1.\tConv1D(21→32, k=3, s=3)\n","•\tWhy? Learns local time-window patterns (e.g. short-term momentum or spread shifts) while immediately coarsening 600→200.\n","2.\tGELU → LayerNorm\n","•\tWhy? Smooth nonlinearity + per-stock+channel normalization to stabilize feature distributions before/after convolution.\n","3.\tConv1D(32→32, k=1)\n","•\tWhy? A “pointwise” mixing of the 32 channels, analogous to a 1×1 conv in vision models. Refines features at each time step.\n","4.\tStockAttention\n","•\tWhy? Learns which stocks’ 200×32 representations should inform one another in this time bucket.\n","•\tA full 112×112 weight matrix allows every stock’s latent representation to borrow information from every other.\n","5.\tStock Embedding\n","•\tWhy? Provides a learned “bias” per stock so the network can distinguish them beyond their raw order-book features.\n","6.\tGRU (32→32)\n","•\tWhy? Captures the sequential dynamics within each stock’s 200-step series, integrating patterns over time.\n","7.\tTimeAttention\n","•\tWhy? Rather than simply averaging or taking the final hidden state, the model learns to focus on those time steps most predictive of realized volatility.\n","8.\tLinear → Affine → exp\n","•\tWhy? Projects the 32-dim attended vector down to a single log-volatility score, rescales (to match data distribution), and exponentiates back to the volatility domain.\n"]},{"cell_type":"markdown","metadata":{"id":"LngrRcFpWDfk"},"source":["[ INPUT ]\n"," • X shape = (B, S=112, T′=⌊600/coarsen⌋, F=21)\n"," • raw book & trade features + engineered waps/log-returns/spreads/imbalances  \n"," • each feature standardized per stock\n","\n","\n","[ Conv1d #1 ]\n"," • in_channels = 21  \n"," • out_channels = D  (e.g. 32)  \n"," • kernel = k₁ (e.g. 3), stride = s₁ (e.g. 3)  \n"," → output shape = (B, S, T₁=⌊T′/s₁⌋, D)\n","\n","\n","[ GELU activation ]\n","\n","\n","[ LayerNorm over (stocks S, features D) ]\n"," • normalize across dims 2 & 3  \n"," → (B, S, T₁, D)\n","\n","\n","[ Conv1d #2 ]\n"," • in_channels = D → out_channels = D  \n"," • kernel = 1, stride = 1  \n"," → (B, S, T₁, D)\n","\n","\n","[ GELU activation ]\n","\n","\n","[ LayerNorm over (stocks S, features D) ]\n"," → (B, S, T₁, D)\n","\n","\n","[ StockAttention ]\n"," • learnable Wₛ ∈ ℝ^(S×S), bₛ ∈ ℝ^S  \n"," • softmax over stocks → aₛ scores (shape S)  \n"," • y = ∑_{j=1..S} x_{…j…} · aₛⱼ + current-stock embedding  \n"," → (B, S, T₁, D)\n","\n","\n","[ reshape for RNN ]\n"," (B, S, T₁, D) → ((B·S), T₁, D)\n","\n","\n","[ GRU ]\n"," • input_size = D, hidden_size = D  \n"," • num_layers, dropout…  \n"," → outputs ((B·S), T₁, D)\n","\n","\n","[ reshape back ]\n"," ((B·S), T₁, D) → (B, S, T₁, D)\n","\n","\n","[ TimeAttention ]\n"," • learnable wₜ ∈ ℝ^(T₁)  \n"," • softmax over time → aₜ scores  \n"," • compress via ∑_{t=1..T₁} x_{…t…}·aₜ  \n"," → (B, S, D)\n","\n","\n","[ Linear → 1 ]\n"," • Dense(D → 1) + bias + learned scaling & shift  \n"," • exp(·)  \n"," → “vol” prediction per stock (shape (B, S))\n","\n","\n","[ LOSS = RMSPE(vol, target) ]"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4927,"status":"ok","timestamp":1745983016710,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"1RDJ92DA1bz4"},"outputs":[],"source":["%%capture\n","!pip install einops\n","!pip install lightning --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5760,"status":"ok","timestamp":1745983022473,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"ixGEC9j_1bz5"},"outputs":[],"source":["import gc\n","import re\n","import os\n","import einops\n","import pandas as pd\n","import numpy as np\n","import xarray as xr\n","import matplotlib.pyplot as plt\n","import ipywidgets as widgets\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import KFold\n","from joblib import Parallel, delayed\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","import lightning.pytorch as pl\n","from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, Callback\n","from lightning.pytorch.loggers import CSVLogger"]},{"cell_type":"code","source":["import lightning.pytorch as pl\n","print(pl, pl.__name__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtDEyzmyWFvw","executionInfo":{"status":"ok","timestamp":1745983022479,"user_tz":240,"elapsed":4,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}},"outputId":"efbcd739-5943-49dc-82ad-f594a6efbbb8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<module 'lightning.pytorch' from '/usr/local/lib/python3.11/dist-packages/lightning/pytorch/__init__.py'> lightning.pytorch\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w8PM9w3PSFNc","executionInfo":{"status":"ok","timestamp":1745983023197,"user_tz":240,"elapsed":717,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}},"outputId":"274ec67e-8e8c-42ce-b1cd-50885f38229a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data_dir = '/content/drive/MyDrive/Colab Notebooks/RBS DL 2025/PRO/data'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"nENivPyq1bz6","executionInfo":{"status":"ok","timestamp":1745983023200,"user_tz":240,"elapsed":1,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["n_features = 21\n","n_stocks = 112\n","n_seconds = 600\n","# if coarsen > 1, data will be aggregated per this number of seconds. used to reduce mem usage\n","coarsen = 3"]},{"cell_type":"markdown","metadata":{"id":"kzm_gLXKIP4d"},"source":["So the four dimensions are:\n","\t1.\tBatch (N)\n","\t2.\tStocks (112 in the competition)\n","\t3.\tTime slices (600 seconds divided by your coarsen stride → e.g. 200)\n","\t4.\tFeatures (21 raw+engineered columns: prices, sizes, log‐returns, spreads, etc.)\n","\n","That 4D structure comes out of our preprocessing in prepare_data, where we:\n","\t•\tRead per-stock parquet files,\n","\t•\tAlign everything on the same time_id×seconds_in_bucket grid,\n","\t•\tEngineer the 21 features,\n","\t•\tCoarsen and stack them into a big NumPy array or xarray with shape (T, S, secs, F),\n","\n","then wrap that into PyTorch datasets to yield mini-batches of shape (batch, S, secs, F)."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XQR4Rzfvc4HH","executionInfo":{"status":"ok","timestamp":1745983023224,"user_tz":240,"elapsed":18,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["def prepare_data(stock_id, stock_ind, set, time_ids, coarsen, norm, out):\n","    #load book data\n","    df_book = pd.read_parquet(f'{data_dir}/book_{set}.parquet/stock_id={stock_id}')\n","    df_min_second = df_book.groupby('time_id').agg(min_second=('seconds_in_bucket', 'min'))\n","    df_book = df_book.merge(df_min_second, left_on='time_id', right_index=True) \\\n","        .eval('seconds_in_bucket = seconds_in_bucket - min_second') \\\n","        .drop('min_second', axis=1)\n","    # load trade data\n","    df_trade = pd.read_parquet(f'{data_dir}/trade_{set}.parquet/stock_id={stock_id}') \\\n","        .merge(df_min_second, left_on='time_id', right_index=True) \\\n","        .eval('seconds_in_bucket = seconds_in_bucket - min_second') \\\n","        .drop('min_second', axis=1)\n","    # merge book + trade\n","    df = pd.merge(df_book, df_trade, on=['time_id', 'seconds_in_bucket'], how='outer')\n","    df['stock_id'] = stock_id\n","    # set multi index\n","    df = df.set_index(['stock_id', 'time_id', 'seconds_in_bucket'])\n","    # pandas -> xarray\n","    df = df.to_xarray().astype('float32')\n","    # processing seconds col to make sure it works fine\n","    df = df.reindex({'time_id': time_ids, 'seconds_in_bucket': np.arange(n_seconds)})\n","    # forward fill imputation: if no new quote, old quote stays active\n","    for name in ['bid_price1', 'bid_price2', 'ask_price1', 'ask_price2',\n","         'bid_size1', 'bid_size2', 'ask_size1', 'ask_size2']:\n","        df[name] = df[name].ffill('seconds_in_bucket')\n","    # wap1/2\n","    df['wap1'] = (df.bid_price1 * df.ask_size1 + df.ask_price1 * df.bid_size1) / (df.bid_size1 + df.ask_size1)\n","    df['wap2'] = (df.bid_price2 * df.ask_size2 + df.ask_price2 * df.bid_size2) / (df.bid_size2 + df.ask_size2)\n","    # log(wap1/2)\n","    df['log_return1'] = np.log(df.wap1).diff('seconds_in_bucket')\n","    df['log_return2'] = np.log(df.wap2).diff('seconds_in_bucket')\n","    df['current_vol'] = (df.log_return1 ** 2).sum('seconds_in_bucket') ** 0.5\n","    df['current_vol_2nd_half'] = (df.log_return1[..., 300:] ** 2).sum('seconds_in_bucket') ** 0.5\n","    # downsmapling if coursen > 1\n","    if coarsen > 1:\n","        mean_features = ['ask_price1', 'ask_price2', 'bid_price1', 'bid_price2',  'ask_size1', 'ask_size2',\n","               'bid_size1', 'bid_size2', 'price']\n","        sum_features = ['size', 'order_count']\n","\n","        df = xr.merge((df[mean_features].coarsen({'seconds_in_bucket': coarsen}, coord_func='min').mean(),\n","                       df[sum_features].coarsen({'seconds_in_bucket': coarsen}, coord_func='min').sum(),\n","                       df[['current_vol', 'current_vol_2nd_half']]))\n","        df['wap1'] = (df.bid_price1 * df.ask_size1 + df.ask_price1 * df.bid_size1) / (df.bid_size1 + df.ask_size1)\n","        df['wap2'] = (df.bid_price2 * df.ask_size2 + df.ask_price2 * df.bid_size2) / (df.bid_size2 + df.ask_size2)\n","        df['log_return1'] = np.log(df.wap1).diff('seconds_in_bucket')\n","        df['log_return2'] = np.log(df.wap2).diff('seconds_in_bucket')\n","    # ba spread\n","    df['spread1'] = df.ask_price1 - df.bid_price1\n","    # order book slope\n","    df['spread2'] = df.ask_price2 - df.ask_price1\n","    df['spread3'] = df.bid_price1 - df.bid_price2\n","    df['total_volume'] = df.ask_size1 + df.ask_size2 + df.bid_size1 + df.bid_size2\n","    df['volume_imbalance1'] = df.ask_size1 + df.ask_size2 - df.bid_size1 - df.bid_size2\n","    df['volume_imbalance2'] = (df.ask_size1 + df.ask_size2 - df.bid_size1 - df.bid_size2) / df.total_volume\n","    for name in ['bid_size1', 'bid_size2', 'ask_size1', 'ask_size2', 'size', 'order_count', 'total_volume']:\n","        df[name] = np.log1p(df[name])\n","        # df[name] = df[name].rank('seconds_in_bucket')\n","    df['volume_imbalance1'] = np.sign(df['volume_imbalance1']) * np.log1p(abs(df['volume_imbalance1']))\n","\n","    df = df.fillna({'ask_price1': 1, 'ask_price2': 1, 'bid_price1': 1, 'bid_price2': 1,  'ask_size1': 0, 'ask_size2': 0,\n","               'bid_size1': 0, 'bid_size2': 0, 'price': 1, 'size': 0, 'order_count': 0, 'wap1': 1, 'wap2': 1,\n","               'log_return1': 0, 'log_return2': 0, 'spread1': 0, 'spread2': 0, 'spread3': 0, 'total_volume': 0,\n","               'volume_imbalance1': 0, 'volume_imbalance2': 0, 'current_vol': 0, 'current_vol_2nd_half': 0})\n","    features = ['ask_price1', 'ask_price2', 'bid_price1', 'bid_price2',  'ask_size1', 'ask_size2',\n","               'bid_size1', 'bid_size2', 'price', 'size', 'order_count', 'wap1', 'wap2',\n","               'log_return1', 'log_return2', 'spread1', 'spread2', 'spread3', 'total_volume',\n","               'volume_imbalance1', 'volume_imbalance2']\n","    extra = ['current_vol', 'current_vol_2nd_half']\n","\n","    if norm is not None:\n","        mean = norm['mean'].sel(stock_id=stock_id)\n","        std = norm['std'].sel(stock_id=stock_id)\n","    else:\n","        mean = df.mean(('time_id', 'seconds_in_bucket')).drop(['current_vol', 'current_vol_2nd_half'])\n","        std = df.std(('time_id', 'seconds_in_bucket')).drop(['current_vol', 'current_vol_2nd_half'])\n","\n","    df.update((df - mean) / std)\n","    df = df.astype('float32')\n","\n","    out[:, stock_ind] = einops.rearrange(df[features].to_array().values, 'f () t sec -> t sec f')\n","    return df[extra], {'mean': mean, 'std': std}"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"D3Yq6DARdG0M","executionInfo":{"status":"ok","timestamp":1745983023225,"user_tz":240,"elapsed":0,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["class OptiverDataset(Dataset):\n","    def __init__(self, features_data, extra_data, time_ids):\n","        self.features_data = features_data\n","        self.extra_data    = extra_data\n","        self.time_ids      = time_ids\n","\n","    def __len__(self):\n","        return len(self.time_ids)\n","\n","    def __getitem__(self, i):\n","        # find the time index\n","        time_id = self.time_ids[i]\n","        t_idx   = self.extra_data.indexes['time_id'].get_loc(time_id)\n","\n","        return {\n","            'data': self.features_data[t_idx],                           # (n_stocks, n_secs, n_feat)\n","            'target': self.extra_data['target'].values[t_idx],             # (n_stocks,)\n","            'current_vol': self.extra_data['current_vol'].values[t_idx],        # (n_stocks,)\n","            'current_vol_2nd_half': self.extra_data['current_vol_2nd_half'].values[t_idx],# (n_stocks,)\n","            'time_id': time_id\n","        }"]},{"cell_type":"markdown","metadata":{"id":"NOuRz3GP4ccR"},"source":["Time Attention Intuition:\n","\n","Maybe volatility spikes at the beginning of a window. Or maybe at the end of a window. Fixed pooling (mean, max) can't adapt to this. This TimeAttention layer learns to adapt dynamically based on data patterns."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"hh0XK_9zg_xV","executionInfo":{"status":"ok","timestamp":1745983023226,"user_tz":240,"elapsed":0,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["# not all seconds are equally informative — attention helps model prioritize\n","class TimeAttention(nn.Module):\n","    # learn which parts of the time window are important\n","    def __init__(self, steps):\n","        super().__init__()\n","        self.steps = steps\n","        self.weights = nn.Parameter(torch.zeros(steps))\n","\n","    # the forward pass - collpases time dimension in a weighted manner\n","    def forward(self, x):\n","        # x: (b, st, t, f)\n","        attn = F.softmax(self.weights, 0)\n","        x = torch.einsum('b s t f, t -> b s f', x, attn)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"riH_2FSi4O9u"},"source":["Stock Attention Intuition:\n","Each stock might borrow information from other correlated stocks.\n","\n","Example:\n","\n","If stock_10 and stock_25 usually move together, attention will learn to pull information between them. Helps the model generalize better, especially when market events affect multiple stocks."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"vnckGz131W8x","executionInfo":{"status":"ok","timestamp":1745983023275,"user_tz":240,"elapsed":40,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["# You can experiment with other ideas for stock attention: maybe it could be\n","# something like MultiHeadAttention module with keys and queries that depends on current input,\n","# maybe it could be a linear combination of all stocks (full connected layer),maybe you can try sparse softmax\n","\n","class StockAttention(nn.Module):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.zeros((n_stocks, n_stocks)))\n","        self.bias = nn.Parameter(torch.zeros(n_stocks))\n","        self.fc_combine = nn.Linear(dim * 2, dim)\n","\n","    def forward(self, x):\n","        # x: (batch, stock, time, feature)\n","        # compute attention scores across assets\n","        attn = F.softmax(self.weight + self.bias[None, :], dim = -1) # (st, st)\n","        y = torch.einsum('b i ..., j i -> b j ...', x, attn)\n","        x = torch.cat((x, y), -1)\n","        x = self.fc_combine(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3xxWkKcS8OtR","executionInfo":{"status":"ok","timestamp":1745983023281,"user_tz":240,"elapsed":5,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["class OptiverModel(pl.LightningModule):\n","    def __init__(\n","        self,\n","        mode: str = 'multi-stock',\n","        dim: int = 32,\n","        conv1_kernel: int = 3,\n","        rnn_layers: int = 2,\n","        rnn_dropout: float = 0.3,\n","        n_features: int = 21\n","    ):\n","        super().__init__()\n","        self.save_hyperparameters()\n","\n","        # stock embedding\n","        self.stock_emb = nn.Embedding(n_stocks, dim)\n","        self.stock_emb.weight.data.normal_(0, 0.2)\n","\n","        # two conv layers over time\n","        self.conv1 = nn.Conv1d(n_features, dim, conv1_kernel, conv1_kernel)\n","        self.conv2 = nn.Conv1d(dim, dim, 1, 1)\n","        self.norm1 = nn.LayerNorm([n_stocks, dim])\n","        self.norm2 = nn.LayerNorm([n_stocks, dim])\n","\n","        # single GRU\n","        self.rnn = nn.GRU(\n","            dim, dim,\n","            num_layers=rnn_layers,\n","            batch_first=True,\n","            dropout=rnn_dropout\n","        )\n","\n","        # **only one** time-attention head now\n","        self.timesteps_attn = TimeAttention(600 // conv1_kernel // coarsen)\n","\n","        # stock-to-stock attention remains\n","        self.stock_attn = StockAttention(dim)\n","\n","        # single output head\n","        self.fc_out1 = nn.Linear(dim, 1)\n","\n","        # for in-notebook plotting\n","        self.history = pd.DataFrame()\n","\n","    def forward(self, x, stock_ind=None):\n","        b = x.shape[0]  # batch size\n","\n","        # conv1 over time for each stock\n","        x = einops.rearrange(x, 'b st t f -> (b st) f t')\n","        x = self.conv1(x)\n","        x = einops.rearrange(x, '(b st) f t -> b t st f', st=n_stocks)\n","        x = F.gelu(x)\n","        x = self.norm1(x)\n","\n","        # conv2\n","        x = einops.rearrange(x, 'b t st f -> (b st) f t')\n","        x = self.conv2(x)\n","        x = einops.rearrange(x, '(b st) f t -> b t st f', st=n_stocks)\n","        x = F.gelu(x)\n","        x = self.norm2(x)\n","\n","        # back to (b, st, t, f)\n","        x = einops.rearrange(x, 'b t st f -> b st t f')\n","\n","        # stock attention + embedding\n","        x = self.stock_attn(x)\n","        x = x + self.stock_emb.weight[None, :, None, :]\n","\n","        # GRU expects (batch*stocks, time, features)\n","        x = einops.rearrange(x, 'b st t f -> (b st) t f')\n","        x, _ = self.rnn(x)\n","        x = einops.rearrange(x, '(b st) t f -> b st t f', st=n_stocks)\n","\n","        # **single** time attention → output head\n","        x = self.timesteps_attn(x)      # (b, st, dim)\n","        x = self.fc_out1(x)             # (b, st, 1)\n","        x = x * 0.63393 - 5.762331\n","        x = torch.exp(x)                # positive volatility\n","\n","        # return as dict\n","        return {'vol': x[..., 0]}       # (b, st)\n","\n","    def training_step(self, batch, batch_idx):\n","        return self.common_step(batch, 'train')\n","\n","    def validation_step(self, batch, batch_idx):\n","        return self.common_step(batch, 'valid')\n","\n","    def common_step(self, batch, stage):\n","        out = self(batch['data'])\n","        mask = ~torch.isnan(batch['target'])\n","        target = torch.where(mask, batch['target'],\n","                             torch.tensor(1.0, device=self.device))\n","        loss = (((out['vol'] - target) / target) ** 2)[mask].mean().sqrt()\n","\n","        # log for checkpointing & CSV logger\n","        self.log(f'{stage}/loss',     loss, on_step=False, on_epoch=True)\n","        self.log(f'{stage}/vol_loss', loss, on_step=False, on_epoch=True)\n","\n","        return {\n","            'loss':   loss,\n","            'target': batch['target'],\n","            'vol':    out['vol'].detach(),\n","            'time_id': batch['time_id']\n","        }\n","\n","    def common_epoch_end(self, outs, stage):\n","        target = torch.cat([x['target'] for x in outs])\n","        vol    = torch.cat([x['vol']    for x in outs])\n","        mask   = ~torch.isnan(target)\n","        rmspe  = (((vol - target) / target) ** 2)[mask].mean().sqrt()\n","\n","        # epoch-level RMSPE\n","        self.log(f'{stage}/rmspe',\n","                 rmspe,\n","                 prog_bar=True,\n","                 on_step=False,\n","                 on_epoch=True)\n","\n","        # keep for our in-notebook plot\n","        self.history.loc[self.trainer.current_epoch,\n","                         f'{stage}/rmspe'] = rmspe.item()\n","\n","    def on_fit_start(self):\n","        # set up our in-notebook chart\n","        self.history_widget = widgets.Output()\n","        display(self.history_widget)\n","\n","    def configure_optimizers(self):\n","        opt   = Adam(self.parameters(), lr=1e-3)\n","        sched = {\n","            'scheduler': ExponentialLR(opt, 0.93),\n","            'interval':  'epoch'\n","        }\n","        return [opt], [sched]"]},{"cell_type":"code","source":["class HistoryCallback(Callback):\n","    def __init__(self):\n","        super().__init__()\n","        self.history = pd.DataFrame()\n","        self.widget = None\n","\n","    def on_fit_start(self, trainer, pl_module):\n","        # Create an output area for live plotting\n","        self.widget = widgets.Output()\n","        display(self.widget)\n","\n","    def on_train_epoch_end(self, trainer, pl_module, outputs):\n","        # Grab the logged epoch‐level metrics\n","        metrics = trainer.callback_metrics\n","        epoch   = trainer.current_epoch\n","\n","        # Write into our local DataFrame\n","        self.history.loc[epoch, 'train/rmspe'] = metrics['train/rmspe'].cpu().item()\n","        self.history.loc[epoch, 'valid/rmspe'] = metrics['valid/rmspe'].cpu().item()\n","\n","        # Redraw the live plot\n","        with self.widget:\n","            self.widget.clear_output(wait=True)\n","            lo = float(self.history.min().min())\n","            hi = float(self.history.quantile(0.95).max())\n","            padding = (hi - lo) * 0.05\n","            self.history.plot(\n","                color=['C1','C0'],\n","                style=['--','-'],\n","                ylim=[lo - padding, hi]\n","            )\n","            plt.show()"],"metadata":{"id":"ouGglyGFmMdB","executionInfo":{"status":"ok","timestamp":1745983023283,"user_tz":240,"elapsed":1,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZ5t_0Ux1bz7","executionInfo":{"status":"ok","timestamp":1745983229083,"user_tz":240,"elapsed":205799,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}},"outputId":"9c5db051-d9ed-4e34-da97-fbf83627e98d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n","[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    8.7s\n","[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    8.7s\n","[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    8.7s\n","[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    8.7s\n","[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   14.5s\n","[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:   14.6s\n","[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:   14.6s\n","[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:   14.6s\n","[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:   20.9s\n","[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   20.9s\n","[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:   20.9s\n","[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:   20.9s\n","[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:   27.3s\n","[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:   27.3s\n","[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:   27.3s\n","[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:   27.3s\n","[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   33.4s\n","[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:   33.4s\n","[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:   33.4s\n","[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:   33.4s\n","[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:   39.4s\n","[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:   39.4s\n","[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:   39.4s\n","[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   39.4s\n","[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:   45.5s\n","[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:   45.5s\n","[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:   45.5s\n","[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:   45.5s\n","[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:   51.8s\n","[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:   51.8s\n","[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:   51.8s\n","[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:   51.8s\n","[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   58.0s\n","[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:   58.3s\n","[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:   58.3s\n","[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:   58.6s\n","[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:  1.1min\n","[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:  1.1min\n","[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:  1.1min\n","[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:  1.1min\n","[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:  1.2min\n","[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.2min\n","[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:  1.2min\n","[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:  1.2min\n","[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:  1.3min\n","[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:  1.3min\n","[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:  1.3min\n","[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:  1.3min\n","[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:  1.4min\n","[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:  1.4min\n","[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:  1.4min\n","[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:  1.4min\n","[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  1.5min\n","[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:  1.5min\n","[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:  1.5min\n","[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:  1.5min\n","[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:  1.6min\n","[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:  1.6min\n","[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:  1.6min\n","[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:  1.6min\n","[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:  1.7min\n","[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:  1.7min\n","[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:  1.7min\n","[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  1.7min\n","[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:  1.8min\n","[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:  1.8min\n","[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:  1.8min\n","[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:  1.8min\n","[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:  1.9min\n","[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:  1.9min\n","[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:  1.9min\n","[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:  1.9min\n","[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:  2.0min\n","[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:  2.0min\n","[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:  2.0min\n","[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:  2.0min\n","[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:  2.1min\n","[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:  2.1min\n","[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:  2.1min\n","[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:  2.1min\n","[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:  2.2min\n","[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:  2.2min\n","[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:  2.2min\n","[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:  2.2min\n","[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:  2.3min\n","[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:  2.3min\n","[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:  2.3min\n","[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:  2.3min\n","[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:  2.4min\n","[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:  2.4min\n","[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:  2.4min\n","[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:  2.4min\n","[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:  2.5min\n","[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:  2.5min\n","[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:  2.5min\n","[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:  2.5min\n","[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:  2.6min\n","[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:  2.6min\n","[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:  2.6min\n","[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:  2.6min\n","[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:  2.7min\n","[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:  2.7min\n","[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:  2.7min\n","[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:  2.7min\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:  2.8min\n","[Parallel(n_jobs=4)]: Done 108 out of 112 | elapsed:  2.8min remaining:    6.3s\n","[Parallel(n_jobs=4)]: Done 112 out of 112 | elapsed:  2.9min finished\n"]}],"source":["df_train = pd.read_csv(f'{data_dir}/train.csv')\n","train_data = np.memmap('/content/drive/MyDrive/Colab Notebooks/RBS DL 2025/PRO/train.npy', 'float16', 'w+',\n","                       shape=(df_train.time_id.nunique(), n_stocks, n_seconds // coarsen, n_features))\n","\n","res = Parallel(n_jobs=4, verbose=51)(\n","    delayed(prepare_data)(stock_id, stock_ind, 'train', df_train.time_id.unique(), coarsen, None, train_data)\n","    for stock_ind, stock_id in enumerate(df_train.stock_id.unique())\n",")\n","\n","train_extra = xr.concat([x[0] for x in res], 'stock_id')\n","train_extra['target'] = df_train.set_index(['time_id', 'stock_id']).to_xarray()['target'].astype('float32')\n","train_extra = train_extra.transpose('time_id', 'stock_id')\n","train_norm = {\n","    'mean': xr.concat([x[1]['mean'] for x in res], 'stock_id'),\n","    'std': xr.concat([x[1]['std'] for x in res], 'stock_id')\n","}\n","\n","# if you data fits in memory, you can load it entirely from disk, otherwise\n","# training in single-stock mode could be very slow, though it can be OK for multi-stock mode\n","train_data = np.array(train_data)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"5bMAxU_e1bz8","executionInfo":{"status":"ok","timestamp":1745983229091,"user_tz":240,"elapsed":2,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["# 1) split your time_ids into train/valid\n","cv = KFold(n_splits=5, shuffle=True, random_state=1)\n","time_ids = train_extra.indexes['time_id'].values\n","train_idx, valid_idx = next(cv.split(time_ids))\n","\n","# 2) wrap each in our simplified dataset\n","train_ds = OptiverDataset(\n","    features_data = train_data,\n","    extra_data    = train_extra,\n","    time_ids      = time_ids[train_idx],\n",")\n","\n","train_dl = DataLoader(\n","    train_ds,\n","    batch_size=8,\n","    shuffle=True,\n","    num_workers=1,\n","    pin_memory=True,\n","    persistent_workers=True\n",")\n","\n","valid_ds = OptiverDataset(\n","    features_data = train_data,\n","    extra_data    = train_extra,\n","    time_ids      = time_ids[valid_idx],\n",")\n","\n","valid_dl = DataLoader(\n","    valid_ds,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=1,\n","    pin_memory=True,\n","    persistent_workers=True\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"FTbJF0W71bz8","executionInfo":{"status":"ok","timestamp":1745983229096,"user_tz":240,"elapsed":2,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}}},"outputs":[],"source":["model = OptiverModel(dim=32, conv1_kernel=1)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nZlyF86AwbZ","executionInfo":{"status":"ok","timestamp":1745983229155,"user_tz":240,"elapsed":57,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"}},"outputId":"5131f531-ad42-429e-fa88-22f19e644cb8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n","INFO: Using 16bit Automatic Mixed Precision (AMP)\n","INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}],"source":["csv_logger = CSVLogger(\n","    save_dir='logs',\n","    name='optiver'\n",")\n","\n","# monitor whatever metric you care about; here I pick valid/vol_loss\n","checkpoint_cb = ModelCheckpoint(\n","    monitor='valid/vol_loss',   # our RMSPE on vol\n","    mode='min',\n","    save_top_k=1,\n","    filename='epoch{epoch:02d}-vol{valid/vol_loss:.4f}'\n",")\n","\n","early_stop = EarlyStopping(\n","    monitor=\"valid/vol_loss\",   # the metric to watch\n","    patience=5,                 # how many epochs to wait for improvement\n","    mode=\"min\",                 # we want to minimize vol_loss\n","    strict=True,                # error if monitored metric isn’t found\n",")\n","\n","history_cb = HistoryCallback()\n","\n","trainer = pl.Trainer(\n","    devices=1,\n","    accelerator='gpu',\n","    precision=16,\n","    max_epochs=10,\n","    callbacks=[checkpoint_cb, early_stop, history_cb],\n","    logger=csv_logger\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":9880,"status":"error","timestamp":1745983239038,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"o5TzGl2i1bz-","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dd122a589d7d43e1b9a8212211a1a4f8","d83dd5110b51452db068862d1536a695","a7dc2d7ba9674614a401ccee4bb75967","2486c97445414ffdb1a2edbf48b3e878","4125567d83c34d1bad691366d7deba00","88a7abe0021d49e5950ef0253b7ba7d0","7e72e9d251d5427d94418689f454e06b","9f3b0d7cc75a4cae8186ecae9413ead2","f411ee2281274557b02df71a1a86d878","05b04369e2a54ea0bca4f28216f4757a","8e3fefd24e074d11a69effbe653c0009","6e7612f4760c44c981c022ddb3fd9676","06793ebc81044282a3e796592ca579b5","210634f3eb8a45aeb6c2351bcdc3a815","cbe7e3055543408dbbae4cb84b01291c","a4a326ba3d264d15a36cb14e1be5c6c5","da4402c77925455688f0dacf4b750a94","14228c16b8af4a9aa52b8b1b6d15e64b","7900347ade1d4ad68189dcfee9415d4a","9798a7b4435e48f9aa32b0889efabd3a","aeedc8ab02f1425e9d77b6897b6aa9f6","3011bcd3ef134b06b8817fdce89cad9d","aea633521006442cbbc49daa43d3262f","92bb2082f250453fa8b52ddc4fb37716","5f231ce38ed14a56999f3ff5bf2adcb1","f70a4ef08fd04d4590bb1596ff4faf78","d77795cdd5444de4b4868841ec022424","3f01bf8a0e3844c6af1857b9bc9102c8","8b7c50c7bb5a492d8f32a65b22f08ca5","d479fbd4dc124dbaba47a4bf9b1efeb3","2f5d74b313d14e588b8bc836f9ee4bb8","fba44e1b8ec140698d35d1b9f5578e4d","090c353117494cf9ac323ffe3a5d3d4e","2d05c26b53b6402288193cfc5ea3df5d","f476a22836714f5cacbe3c5b608146b0","a539109db87c47eaa12f89f5e56ebf8f","4092f2de8b3a4d5786df78d73d2459ae"]},"outputId":"9c10de90-474a-4181-ab65-07bbce9ad8fe"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","INFO:lightning.pytorch.utilities.rank_zero:You are using a CUDA device ('NVIDIA L4') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd122a589d7d43e1b9a8212211a1a4f8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO: \n","  | Name           | Type           | Params | Mode \n","----------------------------------------------------------\n","0 | stock_emb      | Embedding      | 3.6 K  | train\n","1 | conv1          | Conv1d         | 704    | train\n","2 | conv2          | Conv1d         | 1.1 K  | train\n","3 | norm1          | LayerNorm      | 7.2 K  | train\n","4 | norm2          | LayerNorm      | 7.2 K  | train\n","5 | rnn            | GRU            | 12.7 K | train\n","6 | timesteps_attn | TimeAttention  | 200    | train\n","7 | stock_attn     | StockAttention | 14.7 K | train\n","8 | fc_out1        | Linear         | 33     | train\n","----------------------------------------------------------\n","47.3 K    Trainable params\n","0         Non-trainable params\n","47.3 K    Total params\n","0.189     Total estimated model params size (MB)\n","10        Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","  | Name           | Type           | Params | Mode \n","----------------------------------------------------------\n","0 | stock_emb      | Embedding      | 3.6 K  | train\n","1 | conv1          | Conv1d         | 704    | train\n","2 | conv2          | Conv1d         | 1.1 K  | train\n","3 | norm1          | LayerNorm      | 7.2 K  | train\n","4 | norm2          | LayerNorm      | 7.2 K  | train\n","5 | rnn            | GRU            | 12.7 K | train\n","6 | timesteps_attn | TimeAttention  | 200    | train\n","7 | stock_attn     | StockAttention | 14.7 K | train\n","8 | fc_out1        | Linear         | 33     | train\n","----------------------------------------------------------\n","47.3 K    Trainable params\n","0         Non-trainable params\n","47.3 K    Total params\n","0.189     Total estimated model params size (MB)\n","10        Modules in train mode\n","0         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7dc2d7ba9674614a401ccee4bb75967"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4125567d83c34d1bad691366d7deba00"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n","/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"]},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4a326ba3d264d15a36cb14e1be5c6c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d77795cdd5444de4b4868841ec022424"}},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"HistoryCallback.on_train_epoch_end() missing 1 required positional argument: 'outputs'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-c03a53d64a8f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36mon_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# monitor a metric, otherwise they wouldn't be able to monitor a key logged in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;31m# `LightningModule.on_train_epoch_end`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_train_epoch_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitoring_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_lightning_module_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_train_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_train_epoch_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitoring_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Callback]{callback.state_key}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: HistoryCallback.on_train_epoch_end() missing 1 required positional argument: 'outputs'"]}],"source":["trainer.fit(model, train_dl, valid_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227512,"status":"aborted","timestamp":1745983239101,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"LTlYSzRaDlqG"},"outputs":[],"source":["# (Optional) see exactly what keys were logged\n","print(\"All logged metrics:\", trainer.callback_metrics)\n","\n","# Now print whichever metrics you care about—e.g. the primary volatility loss:\n","print(f\"Final train vol_loss: {trainer.callback_metrics['train/vol_loss']:.5f}\")\n","print(f\"Final valid vol_loss: {trainer.callback_metrics['valid/vol_loss']:.5f}\")\n","\n","# If you also want the overall loss:\n","print(f\"Final train loss:     {trainer.callback_metrics['train/loss']:.5f}\")\n","print(f\"Final valid loss:     {trainer.callback_metrics['valid/loss']:.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227554,"status":"aborted","timestamp":1745983239144,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"CgaUtABE0NlI"},"outputs":[],"source":["# lightning has already saved the best‐ever checkpoint under `checkpoint_cb.best_model_path`\n","best_score = checkpoint_cb.best_model_score\n","best_path  = checkpoint_cb.best_model_path\n","\n","print(f\"✔️  Best valid/vol_loss = {best_score:.5f}\")\n","print(f\"   (checkpoint saved to: {best_path})\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227561,"status":"aborted","timestamp":1745983239152,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"gaC2u5Lb6YNg"},"outputs":[],"source":["best_path  = checkpoint_cb.best_model_path\n","best_score = checkpoint_cb.best_model_score  # torch.Tensor(0.2118)\n","\n","# extract the epoch number from the filename\n","m = re.search(r\"epoch(\\d+)-\", best_path)\n","best_epoch = int(m.group(1)) if m else None\n","\n","print(f\"✔️  Best epoch by valid/vol_loss = {best_epoch}\")\n","print(f\"    Best valid/vol_loss (RMSPE)    = {best_score:.5f}\")\n","print(f\"    Checkpoint path: {best_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227563,"status":"aborted","timestamp":1745983239155,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"9ICw_lSV1bz_"},"outputs":[],"source":["pd.Series(F.softmax(model.timesteps_attn.weights, 0).detach()).plot();"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227563,"status":"aborted","timestamp":1745983239156,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"BdtAoy3M-WYY"},"outputs":[],"source":["# — 1) Load the raw metrics.csv that Lightning’s CSVLogger wrote —\n","#    You should already have defined:\n","#      csv_logger = CSVLogger(...)\n","#      trainer = pl.Trainer(..., logger=csv_logger)\n","#    so that csv_logger.log_dir points to the folder containing metrics.csv.\n","\n","metrics_path = os.path.join(csv_logger.log_dir, \"metrics.csv\")\n","metrics = pd.read_csv(metrics_path)\n","\n","# — 2) Quick sanity check — which columns do you actually have?\n","print(\">>> Logged columns:\", metrics.columns.tolist())\n","print(metrics.head())\n","\n","# — 3) One row per epoch — group & take the mean of the two per-epoch entries —\n","#    (Lightning logs train & val in separate rows, so we average them here)\n","epoch_metrics = (\n","    metrics\n","    .groupby(\"epoch\")[[\"train/vol_loss\", \"valid/vol_loss\"]]\n","    .mean()\n","    .reset_index()\n",")\n","\n","# — 4) Plot it —\n","plt.figure(figsize=(8, 4))\n","plt.plot(\n","    epoch_metrics[\"epoch\"],\n","    epoch_metrics[\"train/vol_loss\"],\n","    label=\"train vol_loss (RMSPE)\",\n",")\n","plt.plot(\n","    epoch_metrics[\"epoch\"],\n","    epoch_metrics[\"valid/vol_loss\"],\n","    \"--\",\n","    label=\"valid vol_loss (RMSPE)\",\n",")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Vol-loss (RMSPE)\")\n","plt.title(\"Train vs. Valid RMSPE over Epochs\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227563,"status":"aborted","timestamp":1745983239157,"user":{"displayName":"Atheesh Krishnan","userId":"12070118553506761681"},"user_tz":240},"id":"IwnDnw481b0A"},"outputs":[],"source":["!rm \"/content/drive/MyDrive/Colab Notebooks/RBS DL 2025/PRO/train.npy\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[{"file_id":"186ALimXuv-w9qJNxbnVCg5hT4Zmpbfg8","timestamp":1745967879144},{"file_id":"1FdNLXHgmNg64IMYyvP4sOvQR_sEodYK9","timestamp":1745957677064},{"file_id":"1qrJJMzwlgVQgcVkrNe5Zo_iUkoyakXQk","timestamp":1745901537608}]},"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":2344753,"sourceId":27233,"sourceType":"competition"}],"dockerImageVersionId":30140,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dd122a589d7d43e1b9a8212211a1a4f8":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_d83dd5110b51452db068862d1536a695","msg_id":"","outputs":[]}},"d83dd5110b51452db068862d1536a695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7dc2d7ba9674614a401ccee4bb75967":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_2486c97445414ffdb1a2edbf48b3e878","msg_id":"","outputs":[]}},"2486c97445414ffdb1a2edbf48b3e878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4125567d83c34d1bad691366d7deba00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88a7abe0021d49e5950ef0253b7ba7d0","IPY_MODEL_7e72e9d251d5427d94418689f454e06b","IPY_MODEL_9f3b0d7cc75a4cae8186ecae9413ead2"],"layout":"IPY_MODEL_f411ee2281274557b02df71a1a86d878"}},"88a7abe0021d49e5950ef0253b7ba7d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05b04369e2a54ea0bca4f28216f4757a","placeholder":"​","style":"IPY_MODEL_8e3fefd24e074d11a69effbe653c0009","value":"Sanity Checking DataLoader 0: 100%"}},"7e72e9d251d5427d94418689f454e06b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e7612f4760c44c981c022ddb3fd9676","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06793ebc81044282a3e796592ca579b5","value":2}},"9f3b0d7cc75a4cae8186ecae9413ead2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_210634f3eb8a45aeb6c2351bcdc3a815","placeholder":"​","style":"IPY_MODEL_cbe7e3055543408dbbae4cb84b01291c","value":" 2/2 [00:00&lt;00:00,  3.31it/s]"}},"f411ee2281274557b02df71a1a86d878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"05b04369e2a54ea0bca4f28216f4757a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e3fefd24e074d11a69effbe653c0009":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e7612f4760c44c981c022ddb3fd9676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06793ebc81044282a3e796592ca579b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"210634f3eb8a45aeb6c2351bcdc3a815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbe7e3055543408dbbae4cb84b01291c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4a326ba3d264d15a36cb14e1be5c6c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da4402c77925455688f0dacf4b750a94","IPY_MODEL_14228c16b8af4a9aa52b8b1b6d15e64b","IPY_MODEL_7900347ade1d4ad68189dcfee9415d4a"],"layout":"IPY_MODEL_9798a7b4435e48f9aa32b0889efabd3a"}},"da4402c77925455688f0dacf4b750a94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeedc8ab02f1425e9d77b6897b6aa9f6","placeholder":"​","style":"IPY_MODEL_3011bcd3ef134b06b8817fdce89cad9d","value":"Epoch 0: 100%"}},"14228c16b8af4a9aa52b8b1b6d15e64b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_aea633521006442cbbc49daa43d3262f","max":383,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92bb2082f250453fa8b52ddc4fb37716","value":383}},"7900347ade1d4ad68189dcfee9415d4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f231ce38ed14a56999f3ff5bf2adcb1","placeholder":"​","style":"IPY_MODEL_f70a4ef08fd04d4590bb1596ff4faf78","value":" 383/383 [00:08&lt;00:00, 44.83it/s, v_num=3]"}},"9798a7b4435e48f9aa32b0889efabd3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"aeedc8ab02f1425e9d77b6897b6aa9f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3011bcd3ef134b06b8817fdce89cad9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aea633521006442cbbc49daa43d3262f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92bb2082f250453fa8b52ddc4fb37716":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f231ce38ed14a56999f3ff5bf2adcb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f70a4ef08fd04d4590bb1596ff4faf78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d77795cdd5444de4b4868841ec022424":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f01bf8a0e3844c6af1857b9bc9102c8","IPY_MODEL_8b7c50c7bb5a492d8f32a65b22f08ca5","IPY_MODEL_d479fbd4dc124dbaba47a4bf9b1efeb3"],"layout":"IPY_MODEL_2f5d74b313d14e588b8bc836f9ee4bb8"}},"3f01bf8a0e3844c6af1857b9bc9102c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fba44e1b8ec140698d35d1b9f5578e4d","placeholder":"​","style":"IPY_MODEL_090c353117494cf9ac323ffe3a5d3d4e","value":"Validation DataLoader 0: 100%"}},"8b7c50c7bb5a492d8f32a65b22f08ca5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d05c26b53b6402288193cfc5ea3df5d","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f476a22836714f5cacbe3c5b608146b0","value":24}},"d479fbd4dc124dbaba47a4bf9b1efeb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a539109db87c47eaa12f89f5e56ebf8f","placeholder":"​","style":"IPY_MODEL_4092f2de8b3a4d5786df78d73d2459ae","value":" 24/24 [00:00&lt;00:00, 39.57it/s]"}},"2f5d74b313d14e588b8bc836f9ee4bb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"fba44e1b8ec140698d35d1b9f5578e4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"090c353117494cf9ac323ffe3a5d3d4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d05c26b53b6402288193cfc5ea3df5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f476a22836714f5cacbe3c5b608146b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a539109db87c47eaa12f89f5e56ebf8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4092f2de8b3a4d5786df78d73d2459ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}